# Preliminary Test Results & Analysis

**Date**: October 25, 2025  
**Dataset**: 225M rows, 19GB, 49 CSV files, 366 days (2024-01-01 to 2024-12-31)

---

## 1. Predicate Frequency Analysis ‚úÖ

### WHERE Clause Patterns
- **`type`**: 80% of queries (4 distinct values) ‚≠ê‚≠ê‚≠ê
- **`day`**: 40% of queries (366 distinct values) ‚≠ê‚≠ê‚≠ê
- **`country`**: 20% of queries (12 distinct values) ‚≠ê‚≠ê

### Time Dimensions Used
- **`day`**: 80% of queries ‚≠ê‚≠ê‚≠ê
- **`minute`**: 40% of queries ‚≠ê‚≠ê

### Key Findings
- **Type partitioning is CRITICAL**: Appears in 80% of queries
- **Day-based filtering is universal**: 80% use day dimension
- **Low cardinality perfect for bitmaps**: type (4), country (12)

---

## 2. Compression Benchmark Results ‚úÖ

### Type Column (4 unique values)
- **Dictionary**: 1.66x compression, 68 MB/s
- **LZ4**: 5.54x compression, **2620 MB/s decompress** ‚≠ê
- **Zlib**: 32x compression, 4172 MB/s decompress
- **Recommendation**: Dictionary + Bitmap index

### Country Column (12 unique values)
- **Dictionary**: Best for low cardinality
- **LZ4**: 2.72x, 2296 MB/s decompress
- **Recommendation**: Dictionary encoding

### Advertiser/Publisher IDs (1000-1600 unique)
- **LZ4**: 1.34x, **3000+ MB/s decompress** ‚≠ê‚≠ê‚≠ê
- **Zlib**: 2.47x, 938 MB/s decompress
- **Recommendation**: LZ4 (fast decompression critical)

### Bid Price (67% NULL, 43K unique)
- **LZ4**: 1.12x, **3363 MB/s decompress** ‚≠ê‚≠ê‚≠ê
- **Sparse encoding needed** (67% NULL)
- **Recommendation**: LZ4 + null bitmap

### Key Findings
- **LZ4 decompression is BLAZING FAST**: 2-3 GB/s on M2
- **Dictionary perfect for low-cardinality**: type, country
- **Sparse encoding critical**: bid_price (67% NULL), total_price (100% NULL in sample)

---

## 3. Data Distribution Analysis ‚úÖ

### Row Counts (Extrapolated)
```
Total:       225,000,000 rows
serve:       147,537,450 rows (65.6%)  ‚Üê Largest partition
impression:   73,757,160 rows (32.8%)  ‚Üê Most queried
click:         3,686,615 rows ( 1.6%)
purchase:         18,775 rows ( 0.0%)  ‚Üê Tiniest, but important
```

### Type Partitioning Impact
- **serve partition**: Skip 65.6% of data immediately
- **impression queries**: Only scan 32.8% of data
- **purchase queries**: Only scan 0.008% of data (!!)

### Country Distribution
- **US dominates**: 60% of all rows
- **Top 10 countries**: Cover 95% of data
- **Perfect for bitmap index**: Only 12 distinct countries

### Time Distribution
- **366 days** (full year 2024)
- **~615K rows/day** average
- **Highly compressible** with day-based partitioning

### Pre-Aggregation Size Estimates
```
(day, type):                      ~1,461 rows      ‚Üê TINY ‚≠ê‚≠ê‚≠ê
(country, type):                     ~48 rows      ‚Üê TINY ‚≠ê‚≠ê‚≠ê
(advertiser_id, type):            ~6,456 rows      ‚Üê Small ‚≠ê‚≠ê
(day, advertiser_id, type):   ~1,637,366 rows      ‚Üê Medium ‚≠ê
(day, publisher_id, type):    ~1,157,089 rows      ‚Üê Medium ‚≠ê
```

### Key Findings
- **Pre-aggs are TINY**: (day, type) only 1.5K rows!
- **Purchase events are rare**: 0.008% of data (18K rows total)
- **Type partitioning is a MASSIVE win**: 65-99% data skip

---

## 4. Query Selectivity Estimates ‚úÖ

### Q1: Daily Revenue (impression type)
- **Rows to scan**: 73M (32.8% of data)
- **Result size**: 366 rows (one per day)
- **Strategy**: Pre-agg (day, type) ‚Üí **1.5K rows only!**
- **Expected speedup**: 500-1000√ó

### Q2: Publisher Japan (impression + JP + 4 days)
- **Rows to scan**: 24K rows (0.01% of data) after all filters
- **Result size**: ~240 rows
- **Strategy**: Pre-agg (day, publisher, country, type) OR bitmap intersection
- **Expected speedup**: 1000√ó

### Q3: Avg Purchase by Country
- **Rows to scan**: 18K rows (0.008% of data!!)
- **Result size**: 12 rows
- **Strategy**: Pre-agg (country, type) ‚Üí **48 rows only!**
- **Expected speedup**: 10,000√ó (!!)

### Q4: Advertiser Event Counts (no WHERE filter!)
- **Rows to scan**: 225M rows (FULL SCAN)
- **Result size**: 6,456 rows
- **Strategy**: Pre-agg (advertiser_id, type) ‚Üí **6.5K rows only!**
- **Expected speedup**: 1000√ó

### Q5: Minutely Spend (impression + single day)
- **Rows to scan**: 73M rows (all impressions)
- **Result size**: 1,440 rows (minutes in a day)
- **Strategy**: Pre-agg (day, minute, type) OR (minute, type)
- **Expected speedup**: 500-1000√ó

---

## 5. CRITICAL INSIGHTS & STRATEGY ADJUSTMENTS

### ‚úÖ CONFIRMED: Original Strategy is Sound

1. **Type Partitioning is MANDATORY** ‚≠ê‚≠ê‚≠ê
   - 80% query frequency
   - 65-99% data skip depending on query
   - **Expected impact**: 3-10√ó speedup on filtered queries

2. **Pre-Aggregations are TINY** ‚≠ê‚≠ê‚≠ê
   - (day, type): 1.5K rows vs 225M = 150,000√ó reduction
   - (country, type): 48 rows = 4,000,000√ó reduction
   - **Expected impact**: 100-1000√ó speedup on matching queries

3. **LZ4 Compression is Perfect** ‚≠ê‚≠ê‚≠ê
   - 3+ GB/s decompression on M2
   - Good compression ratios (2-5√ó)
   - **Expected impact**: Fit more in memory, faster I/O

4. **Zone Maps will be Effective** ‚≠ê‚≠ê
   - 366 days, ~615K rows/day
   - Day filters in 40% of queries
   - **Expected impact**: 95%+ block skip on date ranges

### ‚ö†Ô∏è ADJUSTMENTS NEEDED

1. **Q4 needs special handling** (no WHERE clause)
   - Full table scan of 225M rows in baseline
   - Pre-agg (advertiser_id, type) reduces to 6.5K rows
   - **MUST build this pre-agg!**

2. **Sparse encoding is critical**
   - bid_price: 67% NULL
   - total_price: 100% NULL (in sample partition)
   - **Add null bitmaps to all columns**

3. **Country bitmap index is cheap**
   - Only 12 distinct values
   - Used in 20% of queries
   - **Build this, it's <1MB**

4. **Purchase partition is TINY**
   - Only 18K rows (0.008%)
   - Can fit entirely in L2 cache
   - **Keep in memory!**

---

## 6. UPDATED OPTIMIZATION PRIORITIES

### Phase 1: Quick Wins (Must Do)
1. **Build 5 pre-aggs**:
   - `(day, type)` ‚Üí 1.5K rows ‚≠ê‚≠ê‚≠ê
   - `(country, type)` ‚Üí 48 rows ‚≠ê‚≠ê‚≠ê
   - `(advertiser_id, type)` ‚Üí 6.5K rows ‚≠ê‚≠ê‚≠ê (for Q4!)
   - `(day, publisher_id, type)` ‚Üí 1.2M rows ‚≠ê‚≠ê
   - `(minute, type)` ‚Üí ~500K rows ‚≠ê‚≠ê

2. **Type-based partitioning** ‚≠ê‚≠ê‚≠ê
   - Split into 4 partitions
   - Estimated sizes:
     - serve: ~12GB (65%)
     - impression: ~6GB (33%)
     - click: ~300MB (1.6%)
     - purchase: ~15MB (0.01%)

3. **Compression** ‚≠ê‚≠ê‚≠ê
   - Dictionary: type, country
   - LZ4: advertiser_id, publisher_id, bid_price, total_price
   - Null bitmaps: bid_price, total_price

### Phase 2: Optimization (Should Do)
1. **Zone maps on day** ‚≠ê‚≠ê
2. **Bitmap indexes** ‚≠ê‚≠ê
   - type (4 values)
   - country (12 values)
3. **Keep purchase partition in memory** ‚≠ê (only 15MB!)

### Phase 3: Polish (Nice to Have)
1. Sorted layout within partitions
2. Query result caching
3. Adaptive block sizing

---

## 7. PROJECTED PERFORMANCE

### Storage Estimates
```
Raw CSV:                    19 GB
After compression (LZ4):    ~6 GB   (3√ó compression)
Pre-aggregations:          ~50 MB   (all 5 combined)
Metadata (zone maps etc):  ~10 MB
TOTAL:                     ~6.1 GB  (68% reduction, well under 100GB limit)
```

### Memory Budget (16GB available, use ~8GB max)
```
Dictionaries:              ~100 MB
Pre-agg indexes:           ~50 MB
Null bitmaps:              ~50 MB
Type/Country bitmaps:      ~10 MB
Purchase partition (full): ~15 MB
Query buffers:             ~500 MB
Column cache (hot blocks): ~6 GB
TOTAL:                     ~7 GB  (within budget!)
```

### Query Performance Estimates
```
Q1 (daily revenue):         13.5s ‚Üí 10-50ms    (270-1350√ó speedup) ‚≠ê‚≠ê‚≠ê
Q2 (publisher JP):          12.4s ‚Üí 5-20ms     (620-2480√ó speedup) ‚≠ê‚≠ê‚≠ê
Q3 (avg purchase):          11.4s ‚Üí 1-5ms      (2280-11400√ó speedup) ‚≠ê‚≠ê‚≠ê
Q4 (advertiser counts):     12.5s ‚Üí 10-50ms    (250-1250√ó speedup) ‚≠ê‚≠ê‚≠ê
Q5 (minutely spend):        15.4s ‚Üí 20-100ms   (154-770√ó speedup) ‚≠ê‚≠ê

TOTAL: 65s ‚Üí 50-250ms       (260-1300√ó speedup)
TARGET: <1s                 ‚úÖ ACHIEVABLE
STRETCH: <500ms             ‚úÖ LIKELY
```

---

## 8. NEXT STEPS

### Immediate (Today)
1. ‚úÖ Predicate analysis - DONE
2. ‚úÖ Compression benchmark - DONE
3. ‚úÖ Data distribution - DONE
4. ‚è≠Ô∏è Build columnar converter (type partitioning + LZ4)
5. ‚è≠Ô∏è Build pre-aggregation engine

### Tomorrow
1. Build query planner & router
2. Implement vectorized execution
3. Correctness tests vs DuckDB

### Before Judging
1. Memory profiling
2. Performance tuning
3. Documentation

---

## 9. CONFIDENCE LEVEL

**Overall**: üü¢üü¢üü¢üü¢‚ö™ (4/5 - High Confidence)

**What we know for certain**:
- ‚úÖ Type partitioning will work (80% query frequency)
- ‚úÖ Pre-aggs are tiny and cover 100% of example queries
- ‚úÖ LZ4 is fast enough (3GB/s decompress)
- ‚úÖ Memory budget is achievable (~7GB)
- ‚úÖ Target <1s total time is realistic

**Remaining risks**:
- ‚ö†Ô∏è Holdout queries might have different GROUP BY patterns (medium risk)
- ‚ö†Ô∏è Numeric parity for AVG/NULL handling (low risk but high impact)
- ‚ö†Ô∏è Cold start performance if judges restart process (medium risk)

**Risk mitigation**:
- Build fast fallback path (columnar + zone maps) for non-matching queries
- Rigorous correctness testing against DuckDB
- Optimize for warm cache but ensure cold start <2s

---

## 10. CONCLUSION

**The preliminary tests STRONGLY validate our optimization strategy.**

Key metrics:
- **Pre-aggs reduce data**: 150,000√ó for some queries
- **Type partitioning**: 3-10√ó speedup
- **LZ4 compression**: 3GB/s decompress, 3√ó compression ratio
- **Total speedup expected**: 260-1300√ó (target: 65√ó)

**We should proceed with confidence.** üöÄ

**Next**: Build the columnar converter and pre-aggregation engine.
